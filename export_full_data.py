import os
import json
import traceback
import xmltodict
from datetime import datetime

# å¼•ç”¨æ ¸å¿ƒæ¨¡å—
try:
    from wxManager.decrypt.get_wx_info import read_info
    from wxManager.decrypt.decrypt_v3 import decrypt_db_file_v3
    import wxManager.db_v3.sns as sns_module 
    from wxManager.db_v3.sns import Sns
except ImportError:
    print("âŒ ä¾èµ–ç¼ºå¤±ï¼šè¯·ç¡®ä¿ wxManager æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•ä¸‹ï¼Œä¸”å·²å®‰è£… requirements.txt")
    exit(1)

def parse_sns_xml(xml_str):
    """
    è§£ææœ‹å‹åœˆ XMLï¼Œæå–æ­£æ–‡å’Œåª’ä½“ï¼ˆå›¾ç‰‡/è§†é¢‘ï¼‰
    """
    if not xml_str:
        return {"text": "", "media": []}
    
    try:
        data = xmltodict.parse(xml_str)
        timeline = data.get('TimelineObject', {})
        
        # 1. æå–æ–‡å­—
        text = timeline.get('contentDesc', '')
        
        # 2. æå–åª’ä½“
        media_list = []
        content_obj = timeline.get('ContentObject', {})
        if content_obj and 'MediaList' in content_obj:
            medias = content_obj['MediaList'].get('Media', [])
            if isinstance(medias, dict):
                medias = [medias]
                
            for m in medias:
                url = m.get('Url', {}).get('#text', '')
                thumb = m.get('Thumb', {}).get('#text', '')
                type_code = m.get('Type', '0') # 2=å›¾ç‰‡, 6=è§†é¢‘
                
                if url or thumb:
                    media_list.append({
                        "type": "video" if type_code == '6' else "image",
                        "url": url if url else thumb,
                        "thumb": thumb
                    })
        return {"text": text, "media": media_list}
    except:
        return {"text": "XMLè§£æå¼‚å¸¸", "media": []}

def process_interactions(sns_driver, feed_id):
    """
    ã€æ–°å¢ã€‘ä¸“é—¨å¤„ç†æ¯æ¡æœ‹å‹åœˆçš„äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµ & è¯„è®ºï¼‰
    """
    comments_data = sns_driver.get_comment(feed_id)
    
    likes_list = []
    comments_list = []
    
    # éå†è¯¥æ¡æœ‹å‹åœˆçš„æ‰€æœ‰äº’åŠ¨è®°å½•
    for c in comments_data:
        # c çš„ç»“æ„å¯¹åº” sns.py ä¸­çš„ SQL æŸ¥è¯¢ç»“æœï¼š
        # [FeedId, CommentId, CreateTime, StrTime, CommentType, Content, FromUserName, ReplyUserName, ReplyId]
        
        c_time = c[3]
        c_type = c[4] # 1=ç‚¹èµ, 2=è¯„è®º, 3=å…¶ä»–
        c_content = c[5]
        sender_wxid = c[6]
        reply_to_wxid = c[7]
        
        if c_type == 1:
            # === å¤„ç†ç‚¹èµ ===
            likes_list.append({
                "wxid": sender_wxid,
                "time": c_time
            })
        elif c_type == 2:
            # === å¤„ç†è¯„è®º ===
            comments_list.append({
                "wxid": sender_wxid,
                "content": c_content,
                "time": c_time,
                "reply_to": reply_to_wxid # å¦‚æœæ˜¯å›å¤åˆ«äººçš„è¯„è®ºï¼Œè¿™é‡Œä¼šæœ‰å€¼
            })
            
    return likes_list, comments_list

def main():
    print("ğŸš€ [Phase 1] å¯åŠ¨å…¨é‡æ•°æ®é‡‡é›†...")

    # --- 1. è·å–å¯†é’¥ ---
    version_path = os.path.join("wxManager", "decrypt", "version_list.json")
    if not os.path.exists(version_path):
        print("âŒ æ‰¾ä¸åˆ° version_list.json")
        return

    with open(version_path, "r", encoding="utf-8") as f:
        version_dict = json.load(f)
    
    print("ğŸ”‘ è¯»å–å¾®ä¿¡ä¿¡æ¯...")
    wx_infos = read_info(version_dict)
    if not wx_infos:
        print("âŒ æœªæ£€æµ‹åˆ°å¾®ä¿¡è¿è¡Œï¼Œè¯·ç™»å½•ã€‚")
        return
    
    user_info = wx_infos[0]
    key = user_info.get('key')
    wx_dir = user_info.get('wx_dir')
    
    if not key or key == 'None':
        print("âŒ å¯†é’¥è·å–å¤±è´¥ã€‚")
        return
        
    print(f"ğŸ‘¤ ç›®æ ‡ç”¨æˆ·: {user_info.get('name')}")

    # --- 2. è§£å¯†æ•°æ®åº“ ---
    output_dir = os.path.abspath("./client_radar_data") # æ•°æ®ç›®å½•æ”¹ä¸ªåï¼Œæ›´æ­£è§„
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    # å¯»æ‰¾ Sns.db
    possible_paths = [
        os.path.join(wx_dir, "Sns.db"),
        os.path.join(wx_dir, "Msg", "Sns.db"),
    ]
    src_db = next((p for p in possible_paths if os.path.exists(p)), None)
    
    if not src_db:
        print("âŒ æœ¬åœ°æœªæ‰¾åˆ° Sns.dbï¼Œè¯·ç¡®ä¿å·²æµè§ˆè¿‡æœ‹å‹åœˆã€‚")
        return

    dst_db = os.path.join(output_dir, "Sns.db")
    print(f"ğŸ”“ æ­£åœ¨è§£å¯†æ•°æ®åº“: {src_db} -> {dst_db}")
    
    success, msg = decrypt_db_file_v3(key, src_db, dst_db)
    if not success:
        print(f"âŒ è§£å¯†å¤±è´¥: {msg}")
        return

    # --- 3. æå–æ•°æ® ---
    print("ğŸ“¥ æ­£åœ¨æå–æœ‹å‹åœˆåŠäº’åŠ¨æ•°æ®...")
    
    # æ³¨å…¥è·¯å¾„åˆ°æ¨¡å—
    sns_module.db_path = dst_db 
    
    sns = Sns()
    if not sns.open_flag:
        sns.init_database(output_dir)

    feeds = sns.get_feeds()
    
    if not feeds:
        print("âš ï¸ æ•°æ®åº“ä¸ºç©ºã€‚å»ºè®®åœ¨ç”µè„‘ä¸Šå¤šåˆ·ä¸€åˆ·æœ‹å‹åœˆå†è¿è¡Œã€‚")
        return

    export_list = []
    
    # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆå¦‚æœæ²¡è£… tqdm å°±ç®€å• printï¼‰
    try:
        from tqdm import tqdm
        iterator = tqdm(feeds, desc="è§£æä¸­", unit="æ¡")
    except ImportError:
        iterator = feeds
        print(f"å…±å‘ç° {len(feeds)} æ¡æ•°æ®ï¼Œå¼€å§‹è§£æ...")

    for item in iterator:
        # item: [FeedId, CreateTime, StrTime, Type, UserName, Status, StringId, Content]
        feed_id = item[0]
        feed_xml = item[7]
        
        # 1. è§£æå†…å®¹
        content_data = parse_sns_xml(feed_xml)
        
        # 2. ã€å…³é”®ã€‘è·å–äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµå’Œè¯„è®ºï¼‰
        # éœ€è¦ä¼ å…¥ feed_id (å¯èƒ½æ˜¯ int æˆ– stringIdï¼Œsns.py é‡Œé€šå¸¸ç”¨ stringId æŸ¥è¯¢)
        # item[6] æ˜¯ StringId (å¦‚ "138402..."), item[0] æ˜¯ FeedId (int)
        # æ ¹æ® sns.py çš„ get_comment å®ç°: where FeedId=? 
        # é€šå¸¸è¿™é‡Œè¦ä¼  FeedId (item[0])ã€‚å¦‚æœä¸è¡Œå†è¯• StringIdã€‚
        likes, comments = process_interactions(sns, feed_id)
        
        # 3. ç»„è£…æ•°æ®
        feed_obj = {
            "id": str(item[6]), # ä½¿ç”¨ StringId ä½œä¸ºå”¯ä¸€æ ‡è¯†æ›´é€šç”¨
            "timestamp": item[1],
            "date": item[2],
            "author_wxid": item[4], # å‘å¸–äººçš„ wxid
            "content": {
                "text": content_data['text'],
                "media": content_data['media']
            },
            "stats": {
                "likes_count": len(likes),
                "comments_count": len(comments)
            },
            "interactions": {
                "likes": likes,       # åŒ…å«ç‚¹èµäººçš„ wxid
                "comments": comments  # åŒ…å«è¯„è®ºäººçš„ wxid å’Œå†…å®¹
            }
        }
        export_list.append(feed_obj)

    # --- 4. ä¿å­˜ ---
    json_path = os.path.join(output_dir, "moments_full.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(export_list, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸé‡‡é›†: {len(export_list)} æ¡æœ‹å‹åœˆ")
    print(f"ğŸ“ æ•°æ®å·²ä¿å­˜: {json_path}")
    print("ğŸ’¡ æç¤ºï¼šç›®å‰çš„ author_wxid å’Œ interactions é‡Œçš„ wxid éƒ½æ˜¯å¾®ä¿¡å·IDï¼ˆå¦‚ wxid_xxxxï¼‰ã€‚")
    print("   åç»­é˜¶æ®µæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ Contact è¡¨æŠŠå®ƒä»¬æ›¿æ¢æˆçœŸå®çš„â€˜å¾®ä¿¡æ˜µç§°â€™ã€‚")

    sns.close()

if __name__ == "__main__":
    main()